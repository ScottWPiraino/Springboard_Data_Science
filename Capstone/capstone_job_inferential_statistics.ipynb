{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# A function to extract the city name from the string giving the location\n",
    "def get_job_city(job_loc):\n",
    "    job_loc_split = str(job_loc).split(\",\")\n",
    "    return(job_loc_split[0])\n",
    "\n",
    "# A function to extract the state from the string giving the location\n",
    "def get_job_state(job_loc):\n",
    "    job_loc_split = str(job_loc).split(\",\")\n",
    "    if len(job_loc_split) > 1:\n",
    "        return(str(job_loc_split[1]).split()[0])\n",
    "    else:\n",
    "        return(\"\")\n",
    "    \n",
    "# A class to fit a first-order phrase model to a series of job titles\n",
    "class PhraseBigram(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, punct_list, stop_list):\n",
    "        self.punct_list = punct_list\n",
    "        self.stop_list = stop_list\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        # Based on code I saw here: https://www.reddit.com/r/learnmachinelearning/comments/5onknw/python_nlp_need_advice_about_gensim_phrasesphraser/\n",
    "        # Initialize stemmer\n",
    "        from gensim.models.phrases import Phrases\n",
    "        from gensim.models.phrases import Phraser\n",
    "        from nltk.stem.lancaster import LancasterStemmer\n",
    "        from nltk import word_tokenize\n",
    "        lancaster_stemmer = LancasterStemmer()\n",
    "        # Set lists of characters/words to exclude\n",
    "        punct_list = self.punct_list\n",
    "        stop_list = self.stop_list\n",
    "        # Get sentence stream from titles\n",
    "        bigram_stream = [[lancaster_stemmer.stem(i.lower()) for i in word_tokenize(sent) if i not in punct_list and i not in stop_list] for sent in list(X)]\n",
    "        bigram = Phraser(Phrases(bigram_stream, min_count=3, threshold=3, delimiter=b' '))\n",
    "        self.bigram = bigram\n",
    "        return(self)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        from gensim.models.phrases import Phrases\n",
    "        from gensim.models.phrases import Phraser\n",
    "        from nltk.stem.lancaster import LancasterStemmer\n",
    "        from nltk import word_tokenize\n",
    "        lancaster_stemmer = LancasterStemmer()\n",
    "        punct_list = self.punct_list\n",
    "        stop_list = self.stop_list\n",
    "        bigram = self.bigram\n",
    "        x_list = []\n",
    "        for j in X:\n",
    "            doc = [lancaster_stemmer.stem(i) for i in word_tokenize(j) if i not in punct_list and i not in stop_list]\n",
    "            x_list.append(\"-\".join(bigram[doc]))\n",
    "            \n",
    "        return(pd.Series(x_list))\n",
    "\n",
    "# Function to use as custom tokenizer for results of PhraseBigram.transform\n",
    "def dash_tokenizer(sent):\n",
    "    return(sent.split(\"-\"))\n",
    "\n",
    "#Get the job metadata and job descriptions that were scraped previously from Indeed in a dataframe\n",
    "job_metadata = pd.read_csv(\"job_ad_metadata_v2.csv\")\n",
    "job_descriptions = pd.read_csv(\"job_ad_descriptions_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialize pipeline for extracting text features\n",
    "title_phrase_model = PhraseBigram([\".\", \"-\", \"_\", \"!\", \"?\", \"[\", \"]\", \"(\", \")\", \"%\", \"$\", \"&\", \",\", \"/\", \":\", \"–\", \" \"], [\"the\", \"of\", \"a\", \"CA\"])\n",
    "job_title_count_vec = CountVectorizer(max_df = 0.95, min_df = 5, stop_words = 'english', tokenizer = dash_tokenizer)\n",
    "title_pipeline = Pipeline([('phrase_model', title_phrase_model), ('count_vec', job_title_count_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit pipeline on full data set\n",
    "title_pipe_fit = title_pipeline.fit(job_metadata.job_title)\n",
    "\n",
    "# Store components of of the fitted pipeline\n",
    "title_phrase_model = title_pipe_fit.named_steps[\"phrase_model\"]\n",
    "title_count_model = title_pipe_fit.named_steps[\"count_vec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create state label as above for jobs for which I was able to scrape a job description\n",
    "job_descriptions_omit = job_descriptions.dropna()\n",
    "\n",
    "# Initialize models for job descriptions\n",
    "descr_phrase_model = PhraseBigram([\".\", \"-\", \"_\", \"!\", \"?\", \"[\", \"]\", \"(\", \")\", \"%\", \"$\", \"&\", \",\", \"/\", \":\", \"–\", \" \", \">\", \"#\", \"@\"], [\"the\", \"of\", \"a\", \"CA\"])\n",
    "descr_count_vec = CountVectorizer(max_df = 0.95, min_df = 20, stop_words = 'english', tokenizer = dash_tokenizer)\n",
    "descr_pipeline = Pipeline([('phrase_model', descr_phrase_model), ('count_vec', descr_count_vec)])\n",
    "\n",
    "# Fit feature models for job descriptions and get transformed features\n",
    "descr_pipe_fit = descr_pipeline.fit(job_descriptions_omit.description)\n",
    "descr_phrase_model = descr_pipe_fit.named_steps[\"phrase_model\"]\n",
    "descr_count_model = descr_pipe_fit.named_steps[\"count_vec\"]\n",
    "descr_transform_dense = descr_count_model.fit_transform(descr_phrase_model.fit_transform(job_descriptions_omit.description)).todense()\n",
    "descr_transform_dense_names = descr_pipe_fit.get_params()[\"count_vec\"].get_feature_names()\n",
    "descr_count_dense = pd.DataFrame(descr_transform_dense)\n",
    "descr_count_dense.columns = descr_transform_dense_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "title_transform_dense = title_count_model.fit_transform(title_phrase_model.fit_transform(job_metadata.job_title)).todense()\n",
    "title_transform_dense_names = title_pipeline.get_params()[\"count_vec\"].get_feature_names()\n",
    "\n",
    "# Refit the models for the titles that also have descriptions\n",
    "title_descr_dense = title_count_model.transform(title_phrase_model.transform(job_descriptions_omit.job_title)).todense()\n",
    "title_descr_dense = pd.DataFrame(title_descr_dense)\n",
    "title_descr_dense.columns = title_transform_dense_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sas</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sas   False  True \n",
       "stat              \n",
       "0        37    790\n",
       "1        12     15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contingency table for a job title containing the token \"stat\" and the description containing the token \"sas\"\n",
    "stat_sas_table = pd.crosstab(title_descr_dense[\"stat\"], descr_count_dense[\"sas\"] == 0)\n",
    "stat_sas_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9536023505546214e-09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get p-value using fisher's exact test\n",
    "sp.stats.fisher_exact(stat_sas_table)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
