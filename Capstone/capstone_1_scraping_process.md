The main data wranging task that I performed for this project is the scraping of job descriptions and metadata. I achieved this in two steps. First, I scraped metadata, including links for individual job descriptions, from Indeed.com's search page. To do this, I modified code by Sung Pil Moon from https://blog.nycdatascience.com/student-works/project-3-web-scraping-company-data-from-indeed-com-and-dice-com/. This code loops over the search page by creating a url for each page of the search, and then pulls out the job ads using an HTML tag. I alter the tag used to extract in individual jobs to capture a larger number of results. This code also loops over each individual job, extracting the relevant metadata using HTML tags. By examining the HTML for inidividual jobs, I identified tags that tag the company name, link for the job decription, job location, and job title. I altered the script to pull out these elements. This data is then placed in a pandas dataframe with one row per job and a column each for the job title, link, location, and company. My code for obtaining the job metadata is [here](https://github.com/ScottWPiraino/Springboard_Data_Science/blob/master/Capstone/scraping/capstone_1_get_job_metadata.ipynb). 
  
Now that I have the job metadata, I access each individual job description using the link that I obtained earlier. I access each link using BeautifulSoup, and then process the resulting HTML my removing tags that contain extraneous content. Some links produce errors when I try to access them. In this case, I handle the error using a try-except statement, and record that an error occured for that link. I store the resulting job derscriptions, along with an indicator of any errors, in a dataframe with the metadata obtained earlier. The code I used to obtain the job descriptions is [here](https://github.com/ScottWPiraino/Springboard_Data_Science/blob/master/Capstone/scraping/capstone_1_get_job_descriptions.ipynb).  
  
The data that I have now is several columns of natural language text, which needs to be processed further. Arguably, this would also fall into the category of "data wranging". However, I will leave this process for a future portion of my capstone because in this case, the main goal is to learn relevant features from the text. Because of this, the processing of the text is strongly linked with modelling that I will do, so I believe it makes sense to discuss those topics together.
